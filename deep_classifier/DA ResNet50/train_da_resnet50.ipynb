{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, GlobalAveragePooling2D, Flatten\n",
    "import orjson\n",
    "from threading import Thread, Lock\n",
    "from queue import Queue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>kind</th>\n",
       "      <th>defect</th>\n",
       "      <th>size</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename kind defect size  \\\n",
       "3   D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "4   D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "11  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "15  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "20  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "\n",
       "   class_name  class  \n",
       "3          RS      3  \n",
       "4          RS      3  \n",
       "11         RS      3  \n",
       "15         RS      3  \n",
       "20         RS      3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../dataset_test_files.pkl', 'rb') as fp:\n",
    "    df_test = pickle.load(fp)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>kind</th>\n",
       "      <th>defect</th>\n",
       "      <th>size</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...</td>\n",
       "      <td>R</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename kind defect size  \\\n",
       "0  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "1  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "2  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    M   \n",
       "5  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    M   \n",
       "6  D:\\desenvolvimento\\datasets\\TRAIN1200 -1200_CO...    R      S    G   \n",
       "\n",
       "  class_name  class  \n",
       "0         RS      3  \n",
       "1         RS      3  \n",
       "2         RS      3  \n",
       "5         RS      3  \n",
       "6         RS      3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../dataset_train_files.pkl', 'rb') as fp:\n",
    "    df_train = pickle.load(fp)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGeneratorSplited(Sequence):\n",
    "    def __init__(self, df, y_col='class_name', batch_size=64, split=0.5, queue_size=100, **kwargs):\n",
    "        self.gen_da = ImageDataGenerator(**kwargs)\n",
    "        self.gen_raw = ImageDataGenerator()\n",
    "        self.length = int(len(df.index) / (batch_size * (1 - split)))\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_da = int(batch_size * split)\n",
    "        self.flow_da = self.gen_da.flow_from_dataframe(df, y_col=y_col, batch_size=self.batch_da)\n",
    "        self.batch_raw = self.batch_size - self.batch_da\n",
    "        self.flow_raw = self.gen_raw.flow_from_dataframe(df, y_col=y_col, batch_size=self.batch_raw)\n",
    "        temp = next(self.flow_raw)\n",
    "        self.shape = (self.length, *temp[0].shape[1:])\n",
    "        self._next_da = Queue(queue_size)\n",
    "        self._next_raw = Queue(queue_size)\n",
    "        self._next_da_thread = self.prepare_da()\n",
    "        self._next_raw_thread = self.prepare_raw()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "    def get_next_da(self):\n",
    "        return self._next_da.get()\n",
    "    \n",
    "    def get_next_raw(self):\n",
    "        return self._next_raw.get()\n",
    "    \n",
    "    def _prepare_next_da(self):\n",
    "        while True:\n",
    "            self._next_da.put(next(self.flow_da))\n",
    "    \n",
    "    def _prepare_next_raw(self):\n",
    "        while True:\n",
    "            self._next_raw.put(next(self.flow_raw))\n",
    "            \n",
    "    def prepare_da(self):\n",
    "        t = Thread(target=self._prepare_next_da)\n",
    "        t.start()\n",
    "        return t\n",
    "    \n",
    "    def prepare_raw(self):\n",
    "        t = Thread(target=self._prepare_next_raw)\n",
    "        t.start()\n",
    "        return t\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        for _ in range(len(self)):\n",
    "            yield self[None]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x_raw, y_raw = self.get_next_raw()\n",
    "        x_da, y_da = self.get_next_da()\n",
    "        return np.vstack((x_raw, x_da)), np.vstack((y_raw, y_da))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 validated image filenames belonging to 4 classes.\n",
      "Found 840 validated image filenames belonging to 4 classes.\n",
      "<__main__.ImageGeneratorSplited object at 0x000001F3DCAD5408>\n",
      "Found 360 validated image filenames belonging to 4 classes.\n",
      "Found 360 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ImageGeneratorSplited at 0x1f3dcab5ec8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = 0.7\n",
    "gen_train = ImageGeneratorSplited(df_train,\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    # zoom_range=[1, 3],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    split=SPLIT\n",
    ")\n",
    "print(gen_train)\n",
    "gen_test = ImageGeneratorSplited(df_test, split=SPLIT)\n",
    "gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(256, 256, 3))\n",
    "base_model = ResNet50V2(False, None, input_tensor=input_tensor)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 64, 64, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 64, 64, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 64, 64, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 64, 64, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 66, 66, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 32, 32, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 32, 32, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 32, 32, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 32, 32, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 32, 32, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 34, 34, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 16, 16, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 16, 16, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 16, 16, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            2052        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,878,596\n",
      "Trainable params: 24,833,156\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# and a logistic layer -- let's say we have 4 classes\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', # Rotina de otimizao, que informa a ml como ajustar o valor dos parmetros para minimizar o erro.\n",
    "              loss='categorical_crossentropy', # Funo de erro que diz o quo erradas esto nossas predies\n",
    "              metrics=['accuracy']) # Lista de mtricas para avaliar o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_da_resnet50v2.json', 'w') as fp:\n",
    "    fp.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 43 steps, validate for 18 steps\n",
      "Epoch 1/100\n",
      "43/43 - 40s - loss: 1.5183 - accuracy: 0.3151 - val_loss: 29857.3570 - val_accuracy: 0.2435\n",
      "Epoch 2/100\n",
      "43/43 - 16s - loss: 1.3064 - accuracy: 0.3945 - val_loss: 590.5282 - val_accuracy: 0.2444\n",
      "Epoch 3/100\n",
      "43/43 - 21s - loss: 1.2705 - accuracy: 0.4031 - val_loss: 224.0049 - val_accuracy: 0.2519\n",
      "Epoch 4/100\n",
      "43/43 - 21s - loss: 1.2484 - accuracy: 0.4113 - val_loss: 99.4598 - val_accuracy: 0.2537\n",
      "Epoch 5/100\n",
      "43/43 - 21s - loss: 1.2018 - accuracy: 0.4476 - val_loss: 5.7814 - val_accuracy: 0.2120\n",
      "Epoch 6/100\n",
      "43/43 - 21s - loss: 1.1479 - accuracy: 0.4829 - val_loss: 33.5133 - val_accuracy: 0.2565\n",
      "Epoch 7/100\n",
      "43/43 - 21s - loss: 1.1385 - accuracy: 0.4914 - val_loss: 15.5099 - val_accuracy: 0.2231\n",
      "Epoch 8/100\n",
      "43/43 - 21s - loss: 1.1727 - accuracy: 0.4790 - val_loss: 5.6113 - val_accuracy: 0.3630\n",
      "Epoch 9/100\n",
      "43/43 - 20s - loss: 1.0826 - accuracy: 0.5397 - val_loss: 2.2462 - val_accuracy: 0.3213\n",
      "Epoch 10/100\n",
      "43/43 - 21s - loss: 1.0820 - accuracy: 0.5483 - val_loss: 3.3973 - val_accuracy: 0.3926\n",
      "Epoch 11/100\n",
      "43/43 - 21s - loss: 1.0766 - accuracy: 0.5599 - val_loss: 6.0369 - val_accuracy: 0.3426\n",
      "Epoch 12/100\n",
      "43/43 - 20s - loss: 1.0228 - accuracy: 0.5851 - val_loss: 2.8726 - val_accuracy: 0.3824\n",
      "Epoch 13/100\n",
      "43/43 - 21s - loss: 0.9813 - accuracy: 0.5947 - val_loss: 2.7176 - val_accuracy: 0.4315\n",
      "Epoch 14/100\n",
      "43/43 - 22s - loss: 0.9765 - accuracy: 0.5879 - val_loss: 2.4034 - val_accuracy: 0.4463\n",
      "Epoch 15/100\n",
      "43/43 - 20s - loss: 0.9750 - accuracy: 0.6085 - val_loss: 2.8965 - val_accuracy: 0.4444\n",
      "Epoch 16/100\n",
      "43/43 - 21s - loss: 0.9485 - accuracy: 0.6078 - val_loss: 2.8056 - val_accuracy: 0.4343\n",
      "Epoch 17/100\n",
      "43/43 - 21s - loss: 0.9380 - accuracy: 0.6055 - val_loss: 1.8454 - val_accuracy: 0.3861\n",
      "Epoch 18/100\n",
      "43/43 - 21s - loss: 0.9035 - accuracy: 0.6362 - val_loss: 2.5387 - val_accuracy: 0.4528\n",
      "Epoch 19/100\n",
      "43/43 - 20s - loss: 0.9211 - accuracy: 0.6178 - val_loss: 1.7440 - val_accuracy: 0.4426\n",
      "Epoch 20/100\n",
      "43/43 - 21s - loss: 0.8717 - accuracy: 0.6407 - val_loss: 9.9605 - val_accuracy: 0.3046\n",
      "Epoch 21/100\n",
      "43/43 - 21s - loss: 0.8718 - accuracy: 0.6418 - val_loss: 2.3016 - val_accuracy: 0.3370\n",
      "Epoch 22/100\n",
      "43/43 - 21s - loss: 0.9098 - accuracy: 0.6310 - val_loss: 2.1624 - val_accuracy: 0.3704\n",
      "Epoch 23/100\n",
      "43/43 - 21s - loss: 0.8593 - accuracy: 0.6527 - val_loss: 2.8497 - val_accuracy: 0.3278\n",
      "Epoch 24/100\n",
      "43/43 - 21s - loss: 0.8161 - accuracy: 0.6643 - val_loss: 2.0755 - val_accuracy: 0.4046\n",
      "Epoch 25/100\n",
      "43/43 - 20s - loss: 0.8172 - accuracy: 0.6591 - val_loss: 1.7445 - val_accuracy: 0.4157\n",
      "Epoch 26/100\n",
      "43/43 - 20s - loss: 0.8024 - accuracy: 0.6634 - val_loss: 3.9941 - val_accuracy: 0.2880\n",
      "Epoch 27/100\n",
      "43/43 - 21s - loss: 0.7682 - accuracy: 0.6912 - val_loss: 2.2629 - val_accuracy: 0.4694\n",
      "Epoch 28/100\n",
      "43/43 - 21s - loss: 0.7912 - accuracy: 0.6722 - val_loss: 2.1500 - val_accuracy: 0.5222\n",
      "Epoch 29/100\n",
      "43/43 - 21s - loss: 0.7657 - accuracy: 0.6864 - val_loss: 5.1724 - val_accuracy: 0.4009\n",
      "Epoch 30/100\n",
      "43/43 - 21s - loss: 0.7503 - accuracy: 0.7017 - val_loss: 2.2768 - val_accuracy: 0.4759\n",
      "Epoch 31/100\n",
      "43/43 - 21s - loss: 0.7563 - accuracy: 0.6950 - val_loss: 4.1856 - val_accuracy: 0.4065\n",
      "Epoch 32/100\n",
      "43/43 - 20s - loss: 0.7258 - accuracy: 0.7112 - val_loss: 4.0414 - val_accuracy: 0.3481\n",
      "Epoch 33/100\n",
      "43/43 - 21s - loss: 0.7215 - accuracy: 0.7103 - val_loss: 2.5113 - val_accuracy: 0.4065\n",
      "Epoch 34/100\n",
      "43/43 - 21s - loss: 0.7396 - accuracy: 0.6916 - val_loss: 3.7587 - val_accuracy: 0.3509\n",
      "Epoch 35/100\n",
      "43/43 - 21s - loss: 0.6621 - accuracy: 0.7283 - val_loss: 1.0122 - val_accuracy: 0.6185\n",
      "Epoch 36/100\n",
      "43/43 - 21s - loss: 0.7457 - accuracy: 0.7051 - val_loss: 7.4494 - val_accuracy: 0.3074\n",
      "Epoch 37/100\n",
      "43/43 - 21s - loss: 0.6821 - accuracy: 0.7257 - val_loss: 3.0966 - val_accuracy: 0.4306\n",
      "Epoch 38/100\n",
      "43/43 - 22s - loss: 0.6401 - accuracy: 0.7406 - val_loss: 1.7880 - val_accuracy: 0.5463\n",
      "Epoch 39/100\n",
      "43/43 - 18s - loss: 0.6348 - accuracy: 0.7356 - val_loss: 7.5373 - val_accuracy: 0.3093\n",
      "Epoch 40/100\n",
      "43/43 - 21s - loss: 0.6413 - accuracy: 0.7399 - val_loss: 1.6047 - val_accuracy: 0.4583\n",
      "Epoch 41/100\n",
      "43/43 - 20s - loss: 0.6602 - accuracy: 0.7376 - val_loss: 4.0404 - val_accuracy: 0.2852\n",
      "Epoch 42/100\n",
      "43/43 - 21s - loss: 0.6551 - accuracy: 0.7354 - val_loss: 2.1432 - val_accuracy: 0.4963\n",
      "Epoch 43/100\n",
      "43/43 - 21s - loss: 0.6564 - accuracy: 0.7440 - val_loss: 12.6100 - val_accuracy: 0.2704\n",
      "Epoch 44/100\n",
      "43/43 - 21s - loss: 0.6186 - accuracy: 0.7522 - val_loss: 5.9442 - val_accuracy: 0.3296\n",
      "Epoch 45/100\n",
      "43/43 - 19s - loss: 0.6290 - accuracy: 0.7609 - val_loss: 8.1715 - val_accuracy: 0.3417\n",
      "Epoch 46/100\n",
      "43/43 - 20s - loss: 0.6110 - accuracy: 0.7584 - val_loss: 1.1290 - val_accuracy: 0.5472\n",
      "Epoch 47/100\n",
      "43/43 - 21s - loss: 0.5980 - accuracy: 0.7691 - val_loss: 2.0890 - val_accuracy: 0.4787\n",
      "Epoch 48/100\n",
      "43/43 - 27s - loss: 0.6136 - accuracy: 0.7579 - val_loss: 17.3552 - val_accuracy: 0.2787\n",
      "Epoch 49/100\n",
      "43/43 - 15s - loss: 0.5902 - accuracy: 0.7590 - val_loss: 6.7218 - val_accuracy: 0.3185\n",
      "Epoch 50/100\n",
      "43/43 - 20s - loss: 0.5573 - accuracy: 0.7807 - val_loss: 1.7702 - val_accuracy: 0.5194\n",
      "Epoch 51/100\n",
      "43/43 - 21s - loss: 0.5548 - accuracy: 0.7818 - val_loss: 4.8985 - val_accuracy: 0.3259\n",
      "Epoch 52/100\n",
      "43/43 - 20s - loss: 0.5590 - accuracy: 0.7724 - val_loss: 1.3907 - val_accuracy: 0.4657\n",
      "Epoch 53/100\n",
      "43/43 - 21s - loss: 0.5239 - accuracy: 0.7878 - val_loss: 1.3274 - val_accuracy: 0.5787\n",
      "Epoch 54/100\n",
      "43/43 - 21s - loss: 0.5632 - accuracy: 0.7852 - val_loss: 3.3348 - val_accuracy: 0.3880\n",
      "Epoch 55/100\n",
      "43/43 - 21s - loss: 0.5695 - accuracy: 0.7732 - val_loss: 1.6125 - val_accuracy: 0.5426\n",
      "Epoch 56/100\n",
      "43/43 - 20s - loss: 0.5638 - accuracy: 0.7740 - val_loss: 2.7892 - val_accuracy: 0.4074\n",
      "Epoch 57/100\n",
      "43/43 - 21s - loss: 0.5304 - accuracy: 0.7758 - val_loss: 4.6953 - val_accuracy: 0.3583\n",
      "Epoch 58/100\n",
      "43/43 - 21s - loss: 0.5128 - accuracy: 0.7900 - val_loss: 2.6056 - val_accuracy: 0.4704\n",
      "Epoch 59/100\n",
      "43/43 - 20s - loss: 0.5863 - accuracy: 0.7732 - val_loss: 5.4667 - val_accuracy: 0.3528\n",
      "Epoch 60/100\n",
      "43/43 - 21s - loss: 0.5492 - accuracy: 0.7826 - val_loss: 1.8683 - val_accuracy: 0.5093\n",
      "Epoch 61/100\n",
      "43/43 - 21s - loss: 0.5704 - accuracy: 0.7747 - val_loss: 4.5257 - val_accuracy: 0.3972\n",
      "Epoch 62/100\n",
      "43/43 - 21s - loss: 0.5079 - accuracy: 0.8001 - val_loss: 0.8710 - val_accuracy: 0.6657\n",
      "Epoch 63/100\n",
      "43/43 - 21s - loss: 0.5269 - accuracy: 0.7904 - val_loss: 5.2167 - val_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "43/43 - 21s - loss: 0.4756 - accuracy: 0.8080 - val_loss: 1.9567 - val_accuracy: 0.4898\n",
      "Epoch 65/100\n",
      "43/43 - 21s - loss: 0.5561 - accuracy: 0.7852 - val_loss: 1.4279 - val_accuracy: 0.5704\n",
      "Epoch 66/100\n",
      "43/43 - 20s - loss: 0.4526 - accuracy: 0.8226 - val_loss: 1.2447 - val_accuracy: 0.5398\n",
      "Epoch 67/100\n",
      "43/43 - 21s - loss: 0.4491 - accuracy: 0.8177 - val_loss: 1.8155 - val_accuracy: 0.4694\n",
      "Epoch 68/100\n",
      "43/43 - 21s - loss: 0.4677 - accuracy: 0.8174 - val_loss: 0.8495 - val_accuracy: 0.6602\n",
      "Epoch 69/100\n",
      "43/43 - 21s - loss: 0.4375 - accuracy: 0.8222 - val_loss: 1.2522 - val_accuracy: 0.5935\n",
      "Epoch 70/100\n",
      "43/43 - 21s - loss: 0.4281 - accuracy: 0.8308 - val_loss: 1.9843 - val_accuracy: 0.4981\n",
      "Epoch 71/100\n",
      "43/43 - 20s - loss: 0.4444 - accuracy: 0.8267 - val_loss: 7.8025 - val_accuracy: 0.3731\n",
      "Epoch 72/100\n",
      "43/43 - 20s - loss: 0.4379 - accuracy: 0.8286 - val_loss: 1.5832 - val_accuracy: 0.5056\n",
      "Epoch 73/100\n",
      "43/43 - 21s - loss: 0.4425 - accuracy: 0.8237 - val_loss: 3.2425 - val_accuracy: 0.4028\n",
      "Epoch 74/100\n",
      "43/43 - 22s - loss: 0.4567 - accuracy: 0.8155 - val_loss: 2.7197 - val_accuracy: 0.4917\n",
      "Epoch 75/100\n",
      "43/43 - 20s - loss: 0.4489 - accuracy: 0.8249 - val_loss: 0.9829 - val_accuracy: 0.6324\n",
      "Epoch 76/100\n",
      "43/43 - 21s - loss: 0.4014 - accuracy: 0.8432 - val_loss: 1.7966 - val_accuracy: 0.4667\n",
      "Epoch 77/100\n",
      "43/43 - 20s - loss: 0.4147 - accuracy: 0.8421 - val_loss: 14.4601 - val_accuracy: 0.2611\n",
      "Epoch 78/100\n",
      "43/43 - 21s - loss: 0.4394 - accuracy: 0.8312 - val_loss: 3.9755 - val_accuracy: 0.3565\n",
      "Epoch 79/100\n",
      "43/43 - 20s - loss: 0.4060 - accuracy: 0.8454 - val_loss: 10.5415 - val_accuracy: 0.2537\n",
      "Epoch 80/100\n",
      "43/43 - 21s - loss: 0.4330 - accuracy: 0.8297 - val_loss: 3.1675 - val_accuracy: 0.4269\n",
      "Epoch 81/100\n",
      "43/43 - 21s - loss: 0.3703 - accuracy: 0.8529 - val_loss: 1.4486 - val_accuracy: 0.5167\n",
      "Epoch 82/100\n",
      "43/43 - 20s - loss: 0.4162 - accuracy: 0.8379 - val_loss: 1.2029 - val_accuracy: 0.6528\n",
      "Epoch 83/100\n",
      "43/43 - 21s - loss: 0.4104 - accuracy: 0.8398 - val_loss: 0.8871 - val_accuracy: 0.6565\n",
      "Epoch 84/100\n",
      "43/43 - 21s - loss: 0.3955 - accuracy: 0.8443 - val_loss: 1.8305 - val_accuracy: 0.5398\n",
      "Epoch 85/100\n",
      "43/43 - 21s - loss: 0.4353 - accuracy: 0.8323 - val_loss: 1.4960 - val_accuracy: 0.5185\n",
      "Epoch 86/100\n",
      "43/43 - 20s - loss: 0.3485 - accuracy: 0.8697 - val_loss: 1.3636 - val_accuracy: 0.5806\n",
      "Epoch 87/100\n",
      "43/43 - 20s - loss: 0.3617 - accuracy: 0.8641 - val_loss: 1.5762 - val_accuracy: 0.4685\n",
      "Epoch 88/100\n",
      "43/43 - 21s - loss: 0.3897 - accuracy: 0.8585 - val_loss: 2.3831 - val_accuracy: 0.4491\n",
      "Epoch 89/100\n",
      "43/43 - 25s - loss: 0.4329 - accuracy: 0.8368 - val_loss: 2.6978 - val_accuracy: 0.3926\n",
      "Epoch 90/100\n",
      "43/43 - 17s - loss: 0.3901 - accuracy: 0.8582 - val_loss: 0.9112 - val_accuracy: 0.7361\n",
      "Epoch 91/100\n",
      "43/43 - 20s - loss: 0.3435 - accuracy: 0.8653 - val_loss: 0.7359 - val_accuracy: 0.7306\n",
      "Epoch 92/100\n",
      "43/43 - 20s - loss: 0.3964 - accuracy: 0.8522 - val_loss: 1.7830 - val_accuracy: 0.4407\n",
      "Epoch 93/100\n",
      "43/43 - 22s - loss: 0.3239 - accuracy: 0.8701 - val_loss: 1.2634 - val_accuracy: 0.6194\n",
      "Epoch 94/100\n",
      "43/43 - 20s - loss: 0.3372 - accuracy: 0.8664 - val_loss: 1.3033 - val_accuracy: 0.5639\n",
      "Epoch 95/100\n",
      "43/43 - 21s - loss: 0.3215 - accuracy: 0.8743 - val_loss: 1.5138 - val_accuracy: 0.6204\n",
      "Epoch 96/100\n",
      "43/43 - 20s - loss: 0.2941 - accuracy: 0.8915 - val_loss: 0.7919 - val_accuracy: 0.7352\n",
      "Epoch 97/100\n",
      "43/43 - 21s - loss: 0.3423 - accuracy: 0.8735 - val_loss: 0.7018 - val_accuracy: 0.7296\n",
      "Epoch 98/100\n",
      "43/43 - 20s - loss: 0.3003 - accuracy: 0.8888 - val_loss: 1.2558 - val_accuracy: 0.5954\n",
      "Epoch 99/100\n",
      "43/43 - 20s - loss: 0.3790 - accuracy: 0.8579 - val_loss: 0.8206 - val_accuracy: 0.6954\n",
      "Epoch 100/100\n",
      "43/43 - 20s - loss: 0.2968 - accuracy: 0.8896 - val_loss: 2.2047 - val_accuracy: 0.4528\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    gen_train, \n",
    "    epochs=100, \n",
    "    verbose=2, \n",
    "    validation_data=gen_test, \n",
    "    callbacks=[\n",
    "    ModelCheckpoint(\n",
    "        'model_da_resnet50v2.{epoch:03d}-{val_accuracy:.4f}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "    TensorBoard(log_dir='logs_da_resnet50v2'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_da_history.json', 'wb') as fp:\n",
    "    fp.write(orjson.dumps({k: np.array(v).tolist() for k, v in history.history.items()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 43 steps, validate for 18 steps\n",
      "Epoch 1/100\n",
      "43/43 - 15s - loss: 0.3276 - accuracy: 0.8784 - val_loss: 2.2194 - val_accuracy: 0.5611\n",
      "Epoch 2/100\n",
      "43/43 - 15s - loss: 0.3461 - accuracy: 0.8705 - val_loss: 1.2041 - val_accuracy: 0.5963\n",
      "Epoch 3/100\n",
      "43/43 - 20s - loss: 0.3516 - accuracy: 0.8683 - val_loss: 1.9452 - val_accuracy: 0.4296\n",
      "Epoch 4/100\n",
      "43/43 - 21s - loss: 0.3264 - accuracy: 0.8689 - val_loss: 1.1884 - val_accuracy: 0.6389\n",
      "Epoch 5/100\n",
      "43/43 - 21s - loss: 0.3412 - accuracy: 0.8653 - val_loss: 1.0302 - val_accuracy: 0.6833\n",
      "Epoch 6/100\n",
      "43/43 - 21s - loss: 0.3014 - accuracy: 0.8896 - val_loss: 0.9010 - val_accuracy: 0.6704\n",
      "Epoch 7/100\n",
      "43/43 - 21s - loss: 0.2880 - accuracy: 0.8903 - val_loss: 1.1642 - val_accuracy: 0.6565\n",
      "Epoch 8/100\n",
      "43/43 - 22s - loss: 0.2641 - accuracy: 0.9001 - val_loss: 1.8715 - val_accuracy: 0.4630\n",
      "Epoch 9/100\n",
      "43/43 - 20s - loss: 0.2783 - accuracy: 0.8990 - val_loss: 0.7289 - val_accuracy: 0.7491\n",
      "Epoch 10/100\n",
      "43/43 - 21s - loss: 0.2533 - accuracy: 0.9091 - val_loss: 0.8376 - val_accuracy: 0.7407\n",
      "Epoch 11/100\n",
      "43/43 - 20s - loss: 0.2655 - accuracy: 0.9065 - val_loss: 1.5018 - val_accuracy: 0.6093\n",
      "Epoch 12/100\n",
      "43/43 - 21s - loss: 0.2767 - accuracy: 0.8948 - val_loss: 2.4338 - val_accuracy: 0.4037\n",
      "Epoch 13/100\n",
      "43/43 - 21s - loss: 0.2729 - accuracy: 0.8967 - val_loss: 4.2474 - val_accuracy: 0.4287\n",
      "Epoch 14/100\n",
      "43/43 - 22s - loss: 0.2779 - accuracy: 0.9031 - val_loss: 2.7834 - val_accuracy: 0.5639\n",
      "Epoch 15/100\n",
      "43/43 - 20s - loss: 0.2427 - accuracy: 0.9135 - val_loss: 1.4909 - val_accuracy: 0.5991\n",
      "Epoch 16/100\n",
      "43/43 - 20s - loss: 0.2033 - accuracy: 0.9281 - val_loss: 1.2594 - val_accuracy: 0.6537\n",
      "Epoch 17/100\n",
      "43/43 - 21s - loss: 0.2292 - accuracy: 0.9143 - val_loss: 1.1036 - val_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "43/43 - 20s - loss: 0.2685 - accuracy: 0.9062 - val_loss: 0.8842 - val_accuracy: 0.6500\n",
      "Epoch 19/100\n",
      "43/43 - 21s - loss: 0.2470 - accuracy: 0.9004 - val_loss: 2.4865 - val_accuracy: 0.4778\n",
      "Epoch 20/100\n",
      "43/43 - 21s - loss: 0.2994 - accuracy: 0.8915 - val_loss: 2.2641 - val_accuracy: 0.4241\n",
      "Epoch 21/100\n",
      "43/43 - 21s - loss: 0.2663 - accuracy: 0.9027 - val_loss: 1.1485 - val_accuracy: 0.6685\n",
      "Epoch 22/100\n",
      "43/43 - 23s - loss: 0.2852 - accuracy: 0.9023 - val_loss: 1.6059 - val_accuracy: 0.5241\n",
      "Epoch 23/100\n",
      "43/43 - 19s - loss: 0.3843 - accuracy: 0.8698 - val_loss: 1.4973 - val_accuracy: 0.5889\n",
      "Epoch 24/100\n",
      "43/43 - 20s - loss: 0.2547 - accuracy: 0.9081 - val_loss: 0.9690 - val_accuracy: 0.6426\n",
      "Epoch 25/100\n",
      "43/43 - 21s - loss: 0.2141 - accuracy: 0.9240 - val_loss: 0.9134 - val_accuracy: 0.6907\n",
      "Epoch 26/100\n",
      "43/43 - 21s - loss: 0.1760 - accuracy: 0.9368 - val_loss: 0.8867 - val_accuracy: 0.6824\n",
      "Epoch 27/100\n",
      "43/43 - 21s - loss: 0.2249 - accuracy: 0.9188 - val_loss: 1.1185 - val_accuracy: 0.7157\n",
      "Epoch 28/100\n",
      "43/43 - 21s - loss: 0.1934 - accuracy: 0.9323 - val_loss: 2.1810 - val_accuracy: 0.5491\n",
      "Epoch 29/100\n",
      "43/43 - 22s - loss: 0.1857 - accuracy: 0.9341 - val_loss: 1.9109 - val_accuracy: 0.6722\n",
      "Epoch 30/100\n",
      "43/43 - 21s - loss: 0.2303 - accuracy: 0.9169 - val_loss: 6.8209 - val_accuracy: 0.3019\n",
      "Epoch 31/100\n",
      "43/43 - 21s - loss: 0.2158 - accuracy: 0.9221 - val_loss: 3.8055 - val_accuracy: 0.4139\n",
      "Epoch 32/100\n",
      "43/43 - 22s - loss: 0.1891 - accuracy: 0.9281 - val_loss: 0.8197 - val_accuracy: 0.7380\n",
      "Epoch 33/100\n",
      "43/43 - 21s - loss: 0.1882 - accuracy: 0.9379 - val_loss: 2.4789 - val_accuracy: 0.4602\n",
      "Epoch 34/100\n",
      "43/43 - 20s - loss: 0.2220 - accuracy: 0.9203 - val_loss: 2.3720 - val_accuracy: 0.3833\n",
      "Epoch 35/100\n",
      "43/43 - 21s - loss: 0.2071 - accuracy: 0.9263 - val_loss: 3.9923 - val_accuracy: 0.3639\n",
      "Epoch 36/100\n",
      "43/43 - 20s - loss: 0.1884 - accuracy: 0.9296 - val_loss: 2.9490 - val_accuracy: 0.4454\n",
      "Epoch 37/100\n",
      "43/43 - 21s - loss: 0.1777 - accuracy: 0.9360 - val_loss: 2.4432 - val_accuracy: 0.4907\n",
      "Epoch 38/100\n",
      "43/43 - 20s - loss: 0.1749 - accuracy: 0.9396 - val_loss: 1.5780 - val_accuracy: 0.5806\n",
      "Epoch 39/100\n",
      "43/43 - 21s - loss: 0.1619 - accuracy: 0.9457 - val_loss: 1.2200 - val_accuracy: 0.6602\n",
      "Epoch 40/100\n",
      "43/43 - 21s - loss: 0.2038 - accuracy: 0.9255 - val_loss: 2.0521 - val_accuracy: 0.5750\n",
      "Epoch 41/100\n",
      "43/43 - 21s - loss: 0.1856 - accuracy: 0.9364 - val_loss: 1.2086 - val_accuracy: 0.6102\n",
      "Epoch 42/100\n",
      "43/43 - 21s - loss: 0.1648 - accuracy: 0.9409 - val_loss: 2.4606 - val_accuracy: 0.5389\n",
      "Epoch 43/100\n",
      "43/43 - 20s - loss: 0.2029 - accuracy: 0.9218 - val_loss: 1.3297 - val_accuracy: 0.5954\n",
      "Epoch 44/100\n",
      "43/43 - 20s - loss: 0.1578 - accuracy: 0.9422 - val_loss: 1.9198 - val_accuracy: 0.5296\n",
      "Epoch 45/100\n",
      "43/43 - 21s - loss: 0.1809 - accuracy: 0.9375 - val_loss: 2.6606 - val_accuracy: 0.5731\n",
      "Epoch 46/100\n",
      "43/43 - 21s - loss: 0.2396 - accuracy: 0.9184 - val_loss: 1.4542 - val_accuracy: 0.6556\n",
      "Epoch 47/100\n",
      "43/43 - 21s - loss: 0.1425 - accuracy: 0.9502 - val_loss: 1.7192 - val_accuracy: 0.6389\n",
      "Epoch 48/100\n",
      "43/43 - 20s - loss: 0.1465 - accuracy: 0.9502 - val_loss: 3.7762 - val_accuracy: 0.5120\n",
      "Epoch 49/100\n",
      "43/43 - 21s - loss: 0.1902 - accuracy: 0.9386 - val_loss: 1.6502 - val_accuracy: 0.5648\n",
      "Epoch 50/100\n",
      "43/43 - 21s - loss: 0.1486 - accuracy: 0.9427 - val_loss: 1.6882 - val_accuracy: 0.5824\n",
      "Epoch 51/100\n",
      "43/43 - 20s - loss: 0.1490 - accuracy: 0.9502 - val_loss: 2.2293 - val_accuracy: 0.5287\n",
      "Epoch 52/100\n",
      "43/43 - 21s - loss: 0.1728 - accuracy: 0.9409 - val_loss: 1.6630 - val_accuracy: 0.6630\n",
      "Epoch 53/100\n",
      "43/43 - 20s - loss: 0.1802 - accuracy: 0.9345 - val_loss: 4.3376 - val_accuracy: 0.4667\n",
      "Epoch 54/100\n",
      "43/43 - 21s - loss: 0.1441 - accuracy: 0.9525 - val_loss: 1.4352 - val_accuracy: 0.6611\n",
      "Epoch 55/100\n",
      "43/43 - 20s - loss: 0.1297 - accuracy: 0.9502 - val_loss: 1.0415 - val_accuracy: 0.7463\n",
      "Epoch 56/100\n",
      "43/43 - 21s - loss: 0.1624 - accuracy: 0.9472 - val_loss: 1.4986 - val_accuracy: 0.6537\n",
      "Epoch 57/100\n",
      "43/43 - 21s - loss: 0.1779 - accuracy: 0.9375 - val_loss: 1.7863 - val_accuracy: 0.6389\n",
      "Epoch 58/100\n",
      "43/43 - 20s - loss: 0.1436 - accuracy: 0.9502 - val_loss: 1.8500 - val_accuracy: 0.5481\n",
      "Epoch 59/100\n",
      "43/43 - 20s - loss: 0.1315 - accuracy: 0.9540 - val_loss: 1.8738 - val_accuracy: 0.5731\n",
      "Epoch 60/100\n",
      "43/43 - 22s - loss: 0.1386 - accuracy: 0.9536 - val_loss: 1.6998 - val_accuracy: 0.5796\n",
      "Epoch 61/100\n",
      "43/43 - 20s - loss: 0.1373 - accuracy: 0.9495 - val_loss: 1.6808 - val_accuracy: 0.6139\n",
      "Epoch 62/100\n",
      "43/43 - 20s - loss: 0.1504 - accuracy: 0.9513 - val_loss: 6.3599 - val_accuracy: 0.4083\n",
      "Epoch 63/100\n",
      "43/43 - 21s - loss: 0.1501 - accuracy: 0.9491 - val_loss: 2.4280 - val_accuracy: 0.5324\n",
      "Epoch 64/100\n",
      "43/43 - 20s - loss: 0.1816 - accuracy: 0.9392 - val_loss: 4.6196 - val_accuracy: 0.4648\n",
      "Epoch 65/100\n",
      "43/43 - 21s - loss: 0.1337 - accuracy: 0.9555 - val_loss: 1.6414 - val_accuracy: 0.6426\n",
      "Epoch 66/100\n",
      "43/43 - 20s - loss: 0.1164 - accuracy: 0.9622 - val_loss: 3.5713 - val_accuracy: 0.5065\n",
      "Epoch 67/100\n",
      "43/43 - 21s - loss: 0.1371 - accuracy: 0.9547 - val_loss: 1.3480 - val_accuracy: 0.6898\n",
      "Epoch 68/100\n",
      "43/43 - 22s - loss: 0.2196 - accuracy: 0.9311 - val_loss: 4.0025 - val_accuracy: 0.4444\n",
      "Epoch 69/100\n",
      "43/43 - 18s - loss: 0.1511 - accuracy: 0.9487 - val_loss: 2.0674 - val_accuracy: 0.5694\n",
      "Epoch 70/100\n",
      "43/43 - 21s - loss: 0.2038 - accuracy: 0.9330 - val_loss: 1.5279 - val_accuracy: 0.6352\n",
      "Epoch 71/100\n",
      "43/43 - 20s - loss: 0.0970 - accuracy: 0.9681 - val_loss: 1.6548 - val_accuracy: 0.6907\n",
      "Epoch 72/100\n",
      "43/43 - 21s - loss: 0.1236 - accuracy: 0.9592 - val_loss: 1.7900 - val_accuracy: 0.6380\n",
      "Epoch 73/100\n",
      "43/43 - 20s - loss: 0.1418 - accuracy: 0.9495 - val_loss: 1.2858 - val_accuracy: 0.6333\n",
      "Epoch 74/100\n",
      "43/43 - 21s - loss: 0.0981 - accuracy: 0.9659 - val_loss: 3.0268 - val_accuracy: 0.5287\n",
      "Epoch 75/100\n",
      "43/43 - 21s - loss: 0.2128 - accuracy: 0.9210 - val_loss: 1.5772 - val_accuracy: 0.6120\n",
      "Epoch 76/100\n",
      "43/43 - 21s - loss: 0.1085 - accuracy: 0.9652 - val_loss: 1.1377 - val_accuracy: 0.6917\n",
      "Epoch 77/100\n",
      "43/43 - 21s - loss: 0.1117 - accuracy: 0.9618 - val_loss: 0.9700 - val_accuracy: 0.7287\n",
      "Epoch 78/100\n",
      "43/43 - 19s - loss: 0.0928 - accuracy: 0.9643 - val_loss: 1.3105 - val_accuracy: 0.6769\n",
      "Epoch 79/100\n",
      "43/43 - 23s - loss: 0.1848 - accuracy: 0.9379 - val_loss: 1.4941 - val_accuracy: 0.5435\n",
      "Epoch 80/100\n",
      "43/43 - 18s - loss: 0.1459 - accuracy: 0.9521 - val_loss: 1.7029 - val_accuracy: 0.6417\n",
      "Epoch 81/100\n",
      "43/43 - 21s - loss: 0.1046 - accuracy: 0.9600 - val_loss: 1.5276 - val_accuracy: 0.6796\n",
      "Epoch 82/100\n",
      "43/43 - 21s - loss: 0.1431 - accuracy: 0.9491 - val_loss: 1.4500 - val_accuracy: 0.5759\n",
      "Epoch 83/100\n",
      "43/43 - 20s - loss: 0.2361 - accuracy: 0.9296 - val_loss: 1.0518 - val_accuracy: 0.6509\n",
      "Epoch 84/100\n",
      "43/43 - 20s - loss: 0.1238 - accuracy: 0.9582 - val_loss: 0.7483 - val_accuracy: 0.7852\n",
      "Epoch 85/100\n",
      "43/43 - 21s - loss: 0.0803 - accuracy: 0.9716 - val_loss: 1.3138 - val_accuracy: 0.7417\n",
      "Epoch 86/100\n",
      "43/43 - 21s - loss: 0.0905 - accuracy: 0.9689 - val_loss: 1.5051 - val_accuracy: 0.6537\n",
      "Epoch 87/100\n",
      "43/43 - 21s - loss: 0.1326 - accuracy: 0.9532 - val_loss: 1.1327 - val_accuracy: 0.7370\n",
      "Epoch 88/100\n",
      "43/43 - 21s - loss: 0.1026 - accuracy: 0.9659 - val_loss: 1.1203 - val_accuracy: 0.7083\n",
      "Epoch 89/100\n",
      "43/43 - 19s - loss: 0.0825 - accuracy: 0.9734 - val_loss: 1.0689 - val_accuracy: 0.7037\n",
      "Epoch 90/100\n",
      "43/43 - 21s - loss: 0.0855 - accuracy: 0.9686 - val_loss: 1.1050 - val_accuracy: 0.7315\n",
      "Epoch 91/100\n",
      "43/43 - 20s - loss: 0.1160 - accuracy: 0.9624 - val_loss: 1.2693 - val_accuracy: 0.5796\n",
      "Epoch 92/100\n",
      "43/43 - 21s - loss: 0.0744 - accuracy: 0.9701 - val_loss: 1.3301 - val_accuracy: 0.6556\n",
      "Epoch 93/100\n",
      "43/43 - 20s - loss: 0.0809 - accuracy: 0.9689 - val_loss: 1.3707 - val_accuracy: 0.6750\n",
      "Epoch 94/100\n",
      "43/43 - 21s - loss: 0.1314 - accuracy: 0.9536 - val_loss: 4.5072 - val_accuracy: 0.4491\n",
      "Epoch 95/100\n",
      "43/43 - 21s - loss: 0.0982 - accuracy: 0.9644 - val_loss: 4.3199 - val_accuracy: 0.4926\n",
      "Epoch 96/100\n",
      "43/43 - 21s - loss: 0.1037 - accuracy: 0.9659 - val_loss: 1.0683 - val_accuracy: 0.7204\n",
      "Epoch 97/100\n",
      "43/43 - 20s - loss: 0.0780 - accuracy: 0.9757 - val_loss: 1.3451 - val_accuracy: 0.7083\n",
      "Epoch 98/100\n",
      "43/43 - 20s - loss: 0.1181 - accuracy: 0.9635 - val_loss: 1.9463 - val_accuracy: 0.5620\n",
      "Epoch 99/100\n",
      "43/43 - 21s - loss: 0.1262 - accuracy: 0.9532 - val_loss: 3.2634 - val_accuracy: 0.5444\n",
      "Epoch 100/100\n",
      "43/43 - 20s - loss: 0.1084 - accuracy: 0.9615 - val_loss: 1.3239 - val_accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    gen_train, \n",
    "    epochs=100, \n",
    "    verbose=2, \n",
    "    validation_data=gen_test, \n",
    "    callbacks=[\n",
    "    ModelCheckpoint(\n",
    "        'model_da_resnet50v2.{epoch:03d}-{val_accuracy:.4f}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "    TensorBoard(log_dir='logs_da_resnet50v2'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_da_history2.json', 'wb') as fp:\n",
    "    fp.write(orjson.dumps({k: np.array(v).tolist() for k, v in history2.history.items()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
